import whisper  # Biblioteca para transcri√ß√£o de √°udio
import torch  # Biblioteca para computa√ß√£o em GPU
import os  # Biblioteca para manipula√ß√£o de arquivos e diret√≥rios
from datetime import datetime  # Biblioteca para manipula√ß√£o de datas

def transcrever_com_nvidia(audio_path, modelo_tamanho="base"):
    """
    Transcreve um √°udio usando a GPU NVIDIA com o Whisper, com otimiza√ß√µes
    para evitar sa√≠das repetitivas e de baixa qualidade.
    """
    print("Iniciando transcri√ß√£o com GPU NVIDIA...")
    
    device = "cpu"  # Inicia com fallback para CPU
    # Tenta configurar o dispositivo para GPU NVIDIA
    if torch.cuda.is_available():
        print("GPU detectada. Usando CUDA.")
        device = "cuda"
    else:
        print("GPU NVIDIA n√£o encontrada. Usando CPU.")

    try:
        # Carrega o modelo no dispositivo detectado (GPU ou CPU)
        model = whisper.load_model(modelo_tamanho, device=device)
        
        # Configura√ß√µes otimizadas para evitar repeti√ß√£o
        resultado = model.transcribe(
            audio_path,
            fp16=torch.cuda.is_available(),  # Usa fp16 apenas se CUDA estiver dispon√≠vel
            language="pt",                   # For√ßa portugu√™s para melhor acur√°cia
            
            # --- PRINCIPAIS MUDAN√áAS AQUI ---
            # Fornece uma lista de temperaturas. O Whisper tentar√° cada uma
            # at√© encontrar uma que passe nos testes de compress√£o e probabilidade.
            temperature=(0.0, 0.2, 0.4, 0.6, 0.8),
            
            # Limiar para a taxa de compress√£o. Ajuda a evitar texto sem sentido e repetitivo.
            compression_ratio_threshold=2.4,
            
            # Limiar para a probabilidade m√©dia dos tokens. Evita frases com baixa confian√ßa.
            logprob_threshold=-0.8,
            
            # --- FIM DAS MUDAN√áAS ---
            
            best_of=5,                      # Aumentado para mais robustez
            verbose=True,                   # Mostra detalhes da transcri√ß√£o
            beam_size=5                     # Usa beam search para melhor precis√£o
        )
        
        return resultado
        
    except Exception as e:
        print(f"Ocorreu um erro durante a transcri√ß√£o: {e}")
        return {"text": f"Erro na transcri√ß√£o: {e}"}

# --- BLOCO PRINCIPAL (USO PR√ÅTICO) ---
if __name__ == "__main__":
    # Configura√ß√µes
    arquivo_audio = "testeM.mp3"  # Caminho do seu arquivo de √°udio
    modelo = "base"               # Tamanho do modelo: tiny, base, small, medium, large
    
    # Executa a transcri√ß√£o
    resultado = transcrever_com_nvidia(arquivo_audio, modelo)
    
    # Extrai o texto transcrito
    texto_transcrito = resultado.get("text", "").strip()

    # Exibe os resultados
    print("\n" + "="*50)
    print("üìÑ TEXTO TRANSCRITO:")
    print("="*50)
    if texto_transcrito:
        print(texto_transcrito)
    else:
        print("Nenhum texto foi transcrito ou ocorreu um erro.")
        
    # --- L√ìGICA DE SALVAMENTO SIMPLIFICADA ---
    # Salva a transcri√ß√£o em um arquivo de texto se houver conte√∫do
    if texto_transcrito:
        try:
            # Cria um nome de arquivo com base na data e hora atuais para ser √∫nico
            data_atual = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
            nome_arquivo = f"transcricao_{data_atual}.txt"
            
            with open(nome_arquivo, "w", encoding="utf-8") as f:
                f.write(texto_transcrito)
                
            print(f"\n‚úÖ Transcri√ß√£o salva com sucesso no arquivo: {nome_arquivo}")
            
        except Exception as e:
            print(f"\n‚ùå Erro ao salvar o arquivo de transcri√ß√£o: {e}")
            #teste